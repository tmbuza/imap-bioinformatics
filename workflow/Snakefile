from snakemake.utils import min_version

min_version("6.10.0")

# Configuration file containing all user-specified settings
configfile: "config/config.yml"

report: "report/workflow.rst"

import os
import csv
import pandas as pd

# METADATA=pd.read_csv('resources/metadata/metadata.csv').loc[0:3]
# ACCESSIONS=METADATA['run'].tolist() # Specify the column containing the accession, in this demo is Run



# Master rule for controlling workflow.
rule all:
	input:
		"index.html",
		
		# expand("data/mothur/process/{dataset}.files", dataset=config["dataset"]),

		# "data/references/silva.v4.align",
		# "data/references/trainset16_022016.pds.fasta",
		# "data/references/trainset16_022016.pds.tax",
		# "data/references/zymo.mock.16S.v4.fasta",
		
		"data/mothur/process/final.shared",
		"data/mothur/process/final.lefse",
		"data/mothur/process/final.biom",
		"data/mothur/process/final.taxonomy",
	
		
		"data/mothur/process/error_analysis/errorinput.fasta",
		"data/mothur/process/error_analysis/errorinput.count_table",
		"data/mothur/process/error_analysis/errorinput.pick.error.summary",

		"data/mothur/process/intermediate/test.trim.contigs.good.unique.summary",

	

# Making mothur-based sample mapping file.
rule make_mapping_files:
	input:
		script="workflow/scripts/makeFile.sh",
	output:
		files=expand("data/mothur/process/{dataset}.files", dataset=config["dataset"]),
	conda:
		"envs/mothur.yml"
	shell:
		"bash {input.script}"


# Downloading and formatting SILVA and RDP reference databases. The v4 region is extracted from 
# SILVA database for use as reference alignment.
rule get_mothur_references:
	output:
		silvaV4="data/references/silva.v4.align",
		rdpFasta="data/references/trainset16_022016.pds.fasta",
		rdpTax="data/references/trainset16_022016.pds.tax"
	conda:
		"envs/mothur.yml"
	shell:
		"bash workflow/scripts/mothurReferences.sh"


# Downloading the Zymo mock sequence files and extracting v4 region for error estimation.
rule get_mothur_zymo_mock:
	input:
		script="workflow/scripts/mothurMock.sh",
		silvaV4="data/references/silva.v4.align",
	output:
		mockV4="data/references/zymo.mock.16S.v4.fasta"
	conda:
		"envs/mothur.yml"
	shell:
		"bash {input.script}"

# Generating master OTU shared file.
rule mothur_process_sequences:
	input:
		script="workflow/scripts/mothur_process_seqs.sh",
		files=expand("data/mothur/process/{dataset}.files", dataset=config["dataset"]),
		silvaV4="data/references/silva.v4.align",
		rdpFasta="data/references/trainset16_022016.pds.fasta",
		rdpTax="data/references/trainset16_022016.pds.tax"
	output:
		contigreport="data/mothur/process/test.contigs_report",
		shared="data/mothur/process/final.shared",
		taxonomy="data/mothur/process/final.taxonomy",
		lefse="data/mothur/process/final.lefse",
		biom="data/mothur/process/final.biom",
		errorfasta="data/mothur/process/error_analysis/errorinput.fasta",
		errorcount="data/mothur/process/error_analysis/errorinput.count_table",
	conda:
		"envs/mothur.yml"
	shell:
		"bash {input.script}"


# Calculate estimated sequencing error rate based on mock sequences.
rule mothur_calculate_errorrate:
	input:
		script="workflow/scripts/mothurError.sh",
		errorfasta=rules.mothur_process_sequences.output.errorfasta,
		errorcount=rules.mothur_process_sequences.output.errorcount,
		mockV4=rules.get_mothur_zymo_mock.output.mockV4
	output:
		summary="data/mothur/process/error_analysis/errorinput.pick.error.summary"
	params:
		mockGroups='-'.join(config["mothurMock"]) # Concatenates all mock group names with hyphens
	conda:
		"envs/mothur.yml"
	shell:
		"bash {input.script} {input.errorfasta} {input.errorcount} {input.mockV4} {params.mockGroups}"


rule remove_intermedeate_files:
	input:
		script="workflow/scripts/mothur_clean_intermediate.sh",	
		contigreport=rules.mothur_process_sequences.output.contigreport,
	output:
		"data/mothur/process/intermediate/test.trim.contigs.good.unique.summary"
	shell:
		"bash {input.script}"


# Get dot rule graphs
rule dot_rules_graph:
	output:
		"dags/rulegraph.svg",       
		"dags/rulegraph.png",
	shell:
		"bash workflow/scripts/rules_dag.sh"


# Get project tree
rule project_tree:
    output:
        tree="results/project_tree.txt",
    shell:
        """
        bash workflow/scripts/tree.sh
        """

# Get smk static report
rule static_snakemake_report:
    output:
        smkhtml="report.html",
        html2png="images/smkreport/screenshot.png"
    shell:
        """
        bash workflow/scripts/smk_html_report.sh
        """

rule deploy_to_github_pages:
    input:
        script="workflow/scripts/render.R",
        rmd="index.Rmd",
        tree="results/project_tree.txt",
        html2png="images/smkreport/screenshot.png",
        rules="dags/rulegraph.svg",
    output:
        doc="index.html",
    shell:
        """
        R -e "library(rmarkdown); render('{input.rmd}')"
        """
