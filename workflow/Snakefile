from snakemake.utils import min_version

min_version("6.10.0")

# Configuration file containing all user-specified settings
configfile: "config/config.yml"

report: "report/workflow.rst"

import os
import csv
import pandas as pd

# METADATA=pd.read_csv('resources/metadata/metadata.csv').loc[0:3]
# ACCESSIONS=METADATA['run'].tolist() # Specify the column containing the accession, in this demo is Run

# Master rule for controlling workflow.
rule all:
	input:
		"mothur_process/final.shared",
		"mothur_process/final.lefse",
		"mothur_process/final.biom",
		"mothur_process/final.taxonomy",
	
		
		"mothur_process/error_analysis/errorinput.fasta",
		"mothur_process/error_analysis/errorinput.count_table",
		"mothur_process/error_analysis/errorinput.pick.error.summary",

		"mothur_process/intermediate/test.trim.contigs.good.unique.summary",
		
		"images/sra_config_cache.png",
		"images/imap_part02.svg",
		"images/imap_part03.svg",
		"images/imap_part04.svg",
		"images/imap_part05.svg",

		# Create group shared files
		"mothur_process/sample.final.shared",
		"mothur_process/mock.final.shared",
		"mothur_process/control.final.shared",

		# # Create subsample shared file
		# "mothur_process/sample.final.0.03.subsample.shared",
		
		# Alpha and Beta diversity analysis
		"mothur_process/sample.final.count.summary",
		"mothur_process/sample.final.groups.summary",
		"mothur_process/sample.final.groups.rarefaction",
		"mothur_process/sample.final.sharedsobs.0.03.lt.dist",
		"mothur_process/sample.final.thetayc.0.03.lt.dist",
		"mothur_process/sample.final.braycurtis.0.03.lt.dist",
		"mothur_process/sample.final.braycurtis.0.03.lt.tre",
		"mothur_process/sample.final.braycurtis.0.03.lt.pcoa.axes",
		"mothur_process/sample.final.braycurtis.0.03.lt.pcoa.loadings",
		"mothur_process/sample.final.braycurtis.0.03.lt.nmds.iters",
		"mothur_process/sample.final.braycurtis.0.03.lt.nmds.stress",
		"mothur_process/sample.final.braycurtis.0.03.lt.nmds.axes",

		# Error analysis
		"mothur_process/error_analysis/errorinput.fasta",
		"mothur_process/error_analysis/errorinput.count_table",
		"mothur_process/error_analysis/errorinput.pick.error.summary",
		

		"index.html",
		
		# expand("mothur_process/{dataset}.files", dataset=config["dataset"]),

		# "data/references/silva.v4.align",
		# "data/references/trainset16_022016.pds.fasta",
		# "data/references/trainset16_022016.pds.tax",
		# "data/references/zymo.mock.16S.v4.fasta",
	

# Making mothur-based sample mapping file.
rule make_mapping_files:
	input:
		script="workflow/scripts/makeFile.sh",
	output:
		files=expand("mothur_process/{dataset}.files", dataset=config["dataset"]),
	conda:
		"envs/mothur.yml"
	shell:
		"bash {input.script}"


# Downloading and formatting SILVA and RDP reference databases. The v4 region is extracted from 
# SILVA database for use as reference alignment.
rule get_mothur_references:
	output:
		silvaV4="data/references/silva.v4.align",
		rdpFasta="data/references/trainset16_022016.pds.fasta",
		rdpTax="data/references/trainset16_022016.pds.tax"
	conda:
		"envs/mothur.yml"
	shell:
		"bash workflow/scripts/mothurReferences.sh"


# Downloading the Zymo mock sequence files and extracting v4 region for error estimation.
rule get_mothur_zymo_mock:
	input:
		script="workflow/scripts/mothurMock.sh",
		silvaV4="data/references/silva.v4.align",
	output:
		mockV4="data/references/zymo.mock.16S.v4.fasta"
	conda:
		"envs/mothur.yml"
	shell:
		"bash {input.script}"

# Generating master OTU shared file.
rule mothur_process_sequences:
	input:
		script="workflow/scripts/mothur_process_seqs.sh",
		files=expand("mothur_process/{dataset}.files", dataset=config["dataset"]),
		silvaV4="data/references/silva.v4.align",
		rdpFasta="data/references/trainset16_022016.pds.fasta",
		rdpTax="data/references/trainset16_022016.pds.tax"
	output:
		contigreport="mothur_process/test.contigs_report",
		shared="mothur_process/final.shared",
		taxonomy="mothur_process/final.taxonomy",
		lefse="mothur_process/final.lefse",
		biom="mothur_process/final.biom",
		errorfasta="mothur_process/error_analysis/errorinput.fasta",
		errorcount="mothur_process/error_analysis/errorinput.count_table",
	conda:
		"envs/mothur.yml"
	shell:
		"bash {input.script}"


# Calculate estimated sequencing error rate based on mock sequences.
rule mothur_calculate_errorrate:
	input:
		script="workflow/scripts/mothurError.sh",
		errorfasta=rules.mothur_process_sequences.output.errorfasta,
		errorcount=rules.mothur_process_sequences.output.errorcount,
		mockV4=rules.get_mothur_zymo_mock.output.mockV4
	output:
		summary="mothur_process/error_analysis/errorinput.pick.error.summary"
	params:
		mockGroups='-'.join(config["mothurMock"]) # Concatenates all mock group names with hyphens
	conda:
		"envs/mothur.yml"
	shell:
		"bash {input.script} {input.errorfasta} {input.errorcount} {input.mockV4} {params.mockGroups}"


rule remove_intermedeate_files:
	input:
		script="workflow/scripts/mothur_clean_intermediate.sh",	
		contigreport=rules.mothur_process_sequences.output.contigreport,
	output:
		"mothur_process/intermediate/test.trim.contigs.good.unique.summary"
	shell:
		"bash {input.script}"


# Splitting master shared file into individual shared file for: i) samples, ii) controls, and iii) mocks.
# This is used for optimal subsampling during downstream steps.
rule samples_mock_control_shared:
	input:
		script="workflow/scripts/mothurSplitShared.sh",
		shared="mothur_process/final.shared"
	output:
		shared=expand("mothur_process/{group}.final.shared", group = config["mothurGroups"])
	params:
		mockGroups='-'.join(config["mothurMock"]), # Concatenates all mock group names with hyphens
		controlGroups='-'.join(config["mothurControl"]) # Concatenates all control group names with hyphens
	conda:
		"envs/mothur.yml"
	shell:
		"bash {input.script} {params.mockGroups} {params.controlGroups}"



# ##################################################################
# #
# # Diversity Metrics 
# #
# #################################################################
rule alpha_beta_diversity:
	input:
		script="workflow/scripts/mothurAlphaBeta.sh",
		# shared="mothur_process/sample.final.shared",
		shared=expand("mothur_process/{group}.final.shared", group = "sample"),
	output:
		subsample="mothur_process/sample.final.0.03.subsample.shared",
		rarefy="mothur_process/sample.final.groups.rarefaction",
	conda:
		"envs/mothur.yml"
	shell:
		"bash {input.script} {input.shared}"


# Get dot rule graphs
rule dot_rules_graph:
	output:
		"dags/rulegraph.svg",
	shell:
		"bash workflow/scripts/rules_dag.sh"


# Get project tree
rule project_tree:
    output:
        tree="results/project_tree.txt",
    shell:
        """
        bash workflow/scripts/tree.sh
        """

# Get smk static report
rule static_snakemake_report:
    output:
        smkhtml="report.html",
        html2png="images/smkreport/screenshot.png",
    shell:
        """
        bash workflow/scripts/smk_html_report.sh
        """

# Images to include in report
rule gather_informative_images:
	output:
		sracache=report("images/sra_config_cache.png", caption="report/sracache.rst", category="SRA cache"),
		part2=report("images/imap_part02.svg", caption="report/srametadata.rst", category="SRA Metadata DAG"),
		part3=report("images/imap_part03.svg", caption="report/srareads.rst", category="Read Download DAG"),
		part4=report("images/imap_part04.svg", caption="report/readqc.rst", category="Read QC DAG"),
		part5=report("images/imap_part05.svg", caption="report/mothurwkflow.rst", category="Mothur DAG"),
	shell:
		"bash workflow/scripts/copy_files.sh"


# User styled report for GHPages
rule deploy_to_github_pages:
    output:
        doc="index.html",
    shell:
        """
        R -e "library(rmarkdown); render('index.Rmd')"
        """
