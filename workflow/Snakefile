# Snakefile
# Snakemake file for 16S pipeline

# Configuration file containing all user-specified settings
configfile: "config/config.yaml"

# Function for aggregating list of raw sequencing files.
mothurSamples = list(set(glob_wildcards(os.path.join('{outdir}/raw/', '{sample}_{readNum, R[12]}_001.fastq.gz')).sample))

sraSamples = list(set(glob_wildcards(os.path.join('{outdir}/raw/', '{sample}_{sraNum, [12]}.fastq.gz')).sample))


rule all:
    input:
        expand("{dbdir}/silva.seed.align", dbdir=config["dbdir"]),
        expand("{dbdir}/trainset16_022016.pds.fasta", dbdir=config["dbdir"]),
        expand("{dbdir}/trainset16_022016.pds.tax", dbdir=config["dbdir"]),
        expand("{dbdir}/zymo.mock.16S.fasta", dbdir=config["dbdir"]),
        expand("{outdir}/{dataset}.files", outdir=config["outdir"], dataset=config["dataset"]),
        expand("{outdir}/{dataset}.trim.contigs.good.unique.fasta", outdir=config["outdir"], dataset=config["dataset"]),
        expand("{outdir}/{dataset}.trim.contigs.good.count_table", outdir=config["outdir"], dataset=config["dataset"]),
        expand("{outdir}/{dataset}.trim.contigs.good.unique.align", outdir=config["outdir"], dataset=config["dataset"]),
        expand("{outdir}/{dataset}.trim.contigs.good.unique.good.filter.unique.fasta", outdir=config["outdir"], dataset=config["dataset"]),
        expand("{outdir}/{dataset}.trim.contigs.good.unique.good.filter.count_table", outdir=config["outdir"], dataset=config["dataset"]),
        expand("{outdir}/{dataset}..trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.fasta", outdir=config["outdir"], dataset=config["dataset"]),
        expand("{outdir}/{dataset}.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pds.wang.pick.taxonomy", outdir=config["outdir"], dataset=config["dataset"]),
        expand("{outdir}/{dataset}.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.count_table", outdir=config["outdir"], dataset=config["dataset"]),
        # "data/mothur/process/sample.final.shared", 
        # "data/mothur/process/mock.final.shared", 
        # "data/mothur/process/control.final.shared"
        "dags/rulegraph.svg",
        "dags/rulegraph.png",
        "dags/dag.svg",
        "dags/dag.png",
        "report/report.html",
        "index.html"

include: "rules/rules_dag.smk"
include: "rules/interactive_report.smk"
include: "rules/render_index.smk"     

	
# SILVA database for use as reference alignment.
rule get_silva_alignements:
	input:
		script="workflow/scripts/mothur_silva.sh"
	output:
		align="{dbdir}/silva.seed.align",
	conda:
		"envs/mothur.yaml"
	shell:
		"bash {input.script}"


# RDP database for use as reference classifier.
rule get_rdp_classifier:
	input:
		script="workflow/scripts/mothur_rdp.sh"
	output:
		rdpFasta="{dbdir}/trainset16_022016.pds.fasta",
		rdpTax="{dbdir}/trainset16_022016.pds.tax"
	conda:
		"envs/mothur.yaml"
	shell:
		"bash {input.script}"


# Downloading the Zymo mock sequence files and extracting v4 region for error estimation.
rule get_zymo_mock:
	input:
		script="workflow/scripts/mothur_zymo_mock.sh",
		refs=rules.get_silva_alignements.output.align
	output:
		mockrefs="{dbdir}/zymo.mock.16S.fasta"
	conda:
		"envs/mothur.yaml"
	shell:
		"bash {input.script}"


rule make_files:
    input:
        script="workflow/scripts/make_files.sh",
    output:
        files="{outdir}/{dataset}.files",
    shell:
        "bash {input.script}"


rule make_contigs:
    input:
        script="workflow/scripts/make_contigs.sh",
        files=rules.make_files.output.files
    output:
        fasta = "{outdir}/{dataset}.trim.contigs.good.unique.fasta",
        ctable = "{outdir}/{dataset}.trim.contigs.good.count_table",
    threads: 2
    shell:
        "bash {input.script} {input.files}"


rule align_n_filter:
    input:
        script="workflow/scripts/align_n_filter.sh",
        fasta=rules.make_contigs.output.fasta,
        ctable=rules.make_contigs.output.ctable,
        refs=expand("{dbdir}/silva.seed.align", dbdir=config["dbdir"]),
    output:
        align = "{outdir}/{dataset}.trim.contigs.good.unique.align",
        fasta = "{outdir}/{dataset}.trim.contigs.good.unique.good.filter.unique.fasta",
        ctable = "{outdir}/{dataset}.trim.contigs.good.unique.good.filter.count_table",
    shell:
        "bash {input.script} {input.refs}"

rule denoise_n_classify_otus:
    input:
        script="workflow/scripts/denoise_n_classify.sh",
        fasta=rules.align_n_filter.output.fasta,
        ctable=rules.align_n_filter.output.ctable,
        fastaref=expand("{dbdir}/trainset16_022016.pds.fasta", dbdir=config["dbdir"]),
        taxref=expand("{dbdir}/trainset16_022016.pds.tax", dbdir=config["dbdir"]),
    output:
        fasta = "{outdir}/{dataset}.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.fasta",
        ctable = "{outdir}/{dataset}.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.count_table",
        taxonomy = "{outdir}/{dataset}.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pds.wang.pick.taxonomy",
    shell:
        "bash {input.script} {input.fastaref} {input.taxref}"


# Splitting shared by group
rule split_otutable:
	input:
		script="workflow/scripts/mothurSplitShared.sh",
	output:
		shared=expand("{outdir}/{group}.final.shared", outdir=config["outdir"], group = config["mothurGroups"])
	params:
		mockGroups='-'.join(config["mothurMock"]),
		controlGroups='-'.join(config["mothurControl"])
	conda:
		"envs/mothur.yaml"
	shell:
		"bash {input.script} {params.mockGroups} {params.controlGroups}"
